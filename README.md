# Pipeline complet de pr√©diction ‚Äì Mod√®le g√©n√©ral & mod√®le hard

Ce projet impl√©mente un syst√®me de pr√©diction en deux √©tages :

1. un **mod√®le g√©n√©ral**, entra√Æn√© sur tout le dataset ;
2. un **mod√®le hard**, sp√©cialis√© dans les cas incertains ou ambigus ;
3. un **syst√®me hybride**, qui combine intelligemment les deux mod√®les pour la pr√©diction finale.

L‚Äôensemble repose sur trois notebooks √† ex√©cuter **dans l‚Äôordre suivant** :

1. `all_mighty_pred.ipynb`
2. `specialized_hard_pred.ipynb`
3. `testDataset.ipynb`

Les sections ci-dessous expliquent pr√©cis√©ment ce que fait chacun d‚Äôeux.

---

## üìò 1. `all_mighty_pred.ipynb` ‚Äî Mod√®le g√©n√©ral (BERT + XGBoost)

Ce notebook est le c≈ìur du pipeline.  
Il construit un mod√®le robuste entra√Æn√© sur **l‚Äôint√©gralit√© du dataset**.

### Il effectue les op√©rations suivantes :

- **Chargement du jeu de donn√©es d‚Äôentra√Ænement**.
- **Pr√©traitement complet** :
  - gestion des features num√©riques et cat√©gorielles,
  - extraction d‚Äôembeddings avec **BERTweetFR** pour le texte,
  - normalisation / encodage.
- **Entra√Ænement du mod√®le g√©n√©ral** (souvent XGBoost ou ensemble optimis√© mais empiriquement le XGBoost tout seul fournit de meilleurs r√©sultats).
- **Production des probabilit√©s du mod√®le g√©n√©ral** :
  - sur le train ‚Üí pour rep√©rer les cas difficiles,
  - sur le test ‚Üí utilis√©es lors de la pr√©diction finale.
- **Export des probabilit√©s sous forme de CSV** :
  - `proba_general_train.csv`
  - `proba_general_test.csv`

Ces fichiers sont n√©cessaires pour le notebook suivant.

---

## üìò 2. `specialized_hard_pred.ipynb` ‚Äî Mod√®le hard sp√©cialis√© (bios + features)

Ce notebook cr√©e un mod√®le secondaire destin√© √† **corriger les erreurs du mod√®le g√©n√©ral**.  
Il se concentre uniquement sur les cas o√π le mod√®le g√©n√©ral est incertain.

### Il r√©alise les √©tapes suivantes :

- **Import des probabilit√©s du mod√®le g√©n√©ral** (issues de `all_mighty_pred.ipynb`).
- **Import du ‚Äúhard set‚Äù** (issues de `misclassified_{i}.ipynb`).
- **Extraction des probas du mod√®le g√©n√©rale issues du ‚Äúhard set‚Äù** :
  - s√©lection des lignes concern√©es via `challenge_id`.
- **Enrichissement des features** :
  - La proba du mod√®le g√©n√©rale : `proba_general`,
  - Son incertitude : `uncertainty_general = |proba_general - 0.5|`,
  - et les features que l'on a s√©lectionn√©es du dataset original.
- **Pr√©traitement d√©di√© au hard set** :
  - TF-IDF + SVD sur les textes,
  - traitement num√©rique / cat√©goriel.
- **Entra√Ænement du mod√®le hard**  
  (ex : XGBoost, ou voting/stacking model XGB + LR + MLP, mais encore une fois, empiriquement, le XGBoost tout seul fournit de meilleurs r√©sultats).
- **D√©termination des cas difficiles du test**.
  - Export de ces sous-dataset dans les misclassified_{i}.csv (le nom provient de l'√©poque o√π l'on selectionnait uniquement les misclassified, mais on a trouv√© de meilleures m√©thodes apr√®s)
- **Export des pr√©dictions du mod√®le hard** :
  - `specialized_predictions.csv`

Ces fichiers sont n√©cessaires pour le notebook `testDataset.ipynb`.

---

## üìò 3. `testDataset.ipynb` ‚Äî Assemblage final & g√©n√©ration de `submission.csv`

Ce notebook combine les pr√©dictions du mod√®le g√©n√©ral et du mod√®le hard pour cr√©er la **pr√©diction finale**.

### Il effectue :

- **Chargement** :
  - des pr√©dictions du g√©n√©ral (`proba_general_test.csv`),
  - des pr√©dictions du hard (`specialized_predictions.csv`),
  - du dataset test pour r√©cup√©rer les `challenge_id`.
- **Syst√®me hybride** :
Le syst√®me hybride combine le mod√®le g√©n√©ral et le mod√®le hard selon la confiance
du mod√®le g√©n√©ral :

- **Si la probabilit√© du mod√®le g√©n√©ral est en dehors de l‚Äôintervalle `[T_low, T_high]` :**  
  ‚Üí on utilise la pr√©diction du **mod√®le g√©n√©ral**

- **Si la probabilit√© du mod√®le g√©n√©ral est √† l‚Äôint√©rieur de l‚Äôintervalle `[T_low, T_high]` :**  
  ‚Üí on utilise la pr√©diction du **mod√®le hard**, sp√©cialis√© dans les cas ambigus

Autrement dit :
Si proba_general ‚àâ [T_low, T_high] ‚Üí pr√©diction = mod√®le g√©n√©ral
Sinon                               ‚Üí pr√©diction = mod√®le hard


- **G√©n√©ration des pr√©dictions finales** (`label`) pour chaque challenge_id.
- **Cr√©ation du fichier de soumission** :
  - `final_predictions.csv`, format :
    ```
    ID,Prediction
    ...
    12345,0
    12346,1
    ...
    ```

---

# üß© Structure des donn√©es attendues

Le pipeline suppose l'existence des fichiers suivants :

- un **Kaggle2025/train.jsonl** contenant :
  - `challenge_id`,
  - features num√©riques / cat√©gorielles,
  - textes (`full_text`, `user_desc`‚Ä¶),
  - le `label` cible.

- un **Kaggle2025/kaggle_test.jsonl** contenant les m√™mes features **sans label**.

Les notebooks g√©n√®rent ensuite leurs propres fichiers interm√©diaires (probabilit√©s, cas difficiles, etc.).

---

# üîß Pr√©requis

- Python ‚â• 3.10 (√©viter 3.13 qui cause des probl√®mes avec ipykernel)
- Jupyter Notebook ou JupyterLab
- D√©pendances Python principales :

```bash
pip install pandas numpy scikit-learn xgboost tqdm matplotlib transformers torch

