{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 0. CONFIGURATION CRITIQUE (KERAS LEGACY)\n",
        "# ==========================================\n",
        "import os\n",
        "# Ces deux lignes forcent l'utilisation de Keras 2 pour la compatibilité HuggingFace\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "os.environ[\"TF_keras_1_compat\"] = \"1\"\n",
        "\n",
        "# --- INSTALLATION ---\n",
        "!pip install -q transformers tensorflow pandas numpy scikit-learn tf-keras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertModel\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from pandas import json_normalize\n",
        "\n",
        "# ==========================================\n",
        "# 1. FEATURE ENGINEERING\n",
        "# ==========================================\n",
        "def advanced_feature_engineering(df):\n",
        "    target_cols = ['user.listed_count', 'user.favourites_count', 'user.statuses_count',\n",
        "                   'quote_count', 'favorite_count', 'retweet_count', 'reply_count',\n",
        "                   'user.followers_count', 'user.friends_count']\n",
        "    for col in target_cols:\n",
        "        if col not in df.columns: df[col] = 0\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "    df['log_followers'] = np.log1p(df['user.followers_count'])\n",
        "    df['log_friends'] = np.log1p(df['user.friends_count'])\n",
        "    df['ratio_log'] = df['log_followers'] - df['log_friends']\n",
        "    df['log_listed'] = np.log1p(df['user.listed_count'])\n",
        "    df['log_statuses'] = np.log1p(df['user.statuses_count'])\n",
        "\n",
        "    if 'created_at' in df.columns and 'user.created_at' in df.columns:\n",
        "        df['tweet_date'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True).dt.tz_localize(None)\n",
        "        df['user_date'] = pd.to_datetime(df['user.created_at'], errors='coerce', utc=True).dt.tz_localize(None)\n",
        "        df['account_age_days'] = (df['tweet_date'] - df['user_date']).dt.days\n",
        "        df['account_age_days'] = df['account_age_days'].fillna(0)\n",
        "    else:\n",
        "        df['account_age_days'] = 0\n",
        "\n",
        "    def get_clean_text(row):\n",
        "        txt = str(row.get('text', ''))\n",
        "        if 'extended_tweet.full_text' in row and not pd.isna(row['extended_tweet.full_text']):\n",
        "            txt = str(row['extended_tweet.full_text'])\n",
        "        return txt\n",
        "    df['final_text'] = df.apply(get_clean_text, axis=1)\n",
        "\n",
        "    if 'user.description' not in df.columns: df['user.description'] = \"\"\n",
        "    df['user_desc'] = df['user.description'].fillna(\"\")\n",
        "    df['desc_len'] = df['user_desc'].apply(len)\n",
        "    df['desc_has_http'] = df['user_desc'].str.contains(r'http', regex=True).fillna(0).astype(int)\n",
        "\n",
        "    df['caps_ratio'] = df['final_text'].apply(lambda x: sum(1 for c in x if c.isupper()) / (len(x)+1))\n",
        "    return df\n",
        "\n",
        "# ==========================================\n",
        "# 2. PRÉPARATION DES DONNÉES\n",
        "# ==========================================\n",
        "print(\"--- Chargement des données ---\")\n",
        "train_df = pd.read_json('train.jsonl', lines=True)\n",
        "test_df = pd.read_json('kaggle_test.jsonl', lines=True)\n",
        "\n",
        "train_df = json_normalize(train_df.to_dict(orient='records'))\n",
        "test_df = json_normalize(test_df.to_dict(orient='records'))\n",
        "\n",
        "train_df = advanced_feature_engineering(train_df)\n",
        "test_df = advanced_feature_engineering(test_df)\n",
        "\n",
        "numeric_features = [\n",
        "    'log_listed', 'log_statuses', 'ratio_log',\n",
        "    'quote_count', 'favorite_count', 'retweet_count',\n",
        "    'caps_ratio', 'desc_len', 'desc_has_http',\n",
        "    'account_age_days'\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_meta = scaler.fit_transform(train_df[numeric_features])\n",
        "X_test_meta = scaler.transform(test_df[numeric_features])\n",
        "y_train = train_df['label'].values\n",
        "\n",
        "print(\"--- Tokenization BERT ---\")\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "MAX_LEN = 64\n",
        "\n",
        "def batch_encode(tokenizer, texts, batch_size=256, max_length=MAX_LEN):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, max_length=max_length, padding='max_length', truncation=True, return_tensors='tf')\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        attention_masks.append(inputs['attention_mask'])\n",
        "    return tf.concat(input_ids, 0), tf.concat(attention_masks, 0)\n",
        "\n",
        "X_train_ids, X_train_mask = batch_encode(tokenizer, train_df['final_text'].tolist())\n",
        "X_test_ids, X_test_mask = batch_encode(tokenizer, test_df['final_text'].tolist())\n",
        "\n",
        "# ==========================================\n",
        "# 3. MODÈLE HYBRIDE\n",
        "# ==========================================\n",
        "print(\"--- Construction du Modèle Hybride ---\")\n",
        "\n",
        "def build_model():\n",
        "    # Inputs\n",
        "    input_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
        "    input_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n",
        "\n",
        "    # BERT (use_safetensors=False est important)\n",
        "    distilbert = TFDistilBertModel.from_pretrained('distilbert-base-uncased', use_safetensors=False)\n",
        "    distilbert.trainable = True\n",
        "\n",
        "    bert_output = distilbert(input_ids, attention_mask=input_mask)[0]\n",
        "    cls_token = bert_output[:, 0, :]\n",
        "    x_text = Dropout(0.2)(cls_token)\n",
        "\n",
        "    # Metadata\n",
        "    input_meta = Input(shape=(X_train_meta.shape[1],), name='input_meta')\n",
        "    x_meta = Dense(32, activation='relu')(input_meta)\n",
        "    x_meta = Dropout(0.2)(x_meta)\n",
        "\n",
        "    # Fusion\n",
        "    combined = Concatenate()([x_text, x_meta])\n",
        "    z = Dense(64, activation='relu')(combined)\n",
        "    z = Dropout(0.2)(z)\n",
        "    output = Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "    model = Model(inputs=[input_ids, input_mask, input_meta], outputs=output)\n",
        "    optimizer = Adam(learning_rate=2e-5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# ==========================================\n",
        "# 4. ENTRAÎNEMENT & PRÉDICTION\n",
        "# ==========================================\n",
        "print(\"--- Début de l'entraînement ---\")\n",
        "\n",
        "# Correction du Bug ModelCheckpoint: On enlève 'save_format' qui n'est plus nécessaire en legacy\n",
        "checkpoint = ModelCheckpoint(\"bert_hybrid.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train_ids, X_train_mask, X_train_meta],\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=4,\n",
        "    batch_size=16,\n",
        "    callbacks=[checkpoint, early_stop]\n",
        ")\n",
        "\n",
        "print(\"--- Prédiction Finale ---\")\n",
        "preds = model.predict([X_test_ids, X_test_mask, X_test_meta], batch_size=16)\n",
        "final_preds = (preds > 0.5).astype(int).reshape(-1)\n",
        "\n",
        "submission = pd.DataFrame({'ID': test_df['challenge_id'], 'Prediction': final_preds})\n",
        "submission.to_csv('submission_BERT_Hybrid.csv', index=False)\n",
        "\n",
        "print(\"Fichier 'submission_BERT_Hybrid.csv' généré avec succès !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFflIosAIyvB",
        "outputId": "5a9421b8-355a-4f35-cdcd-f60ab4d95abe"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Chargement des données ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-199530952.py:43: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['user_date'] = pd.to_datetime(df['user.created_at'], errors='coerce', utc=True).dt.tz_localize(None)\n",
            "/tmp/ipython-input-199530952.py:43: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['user_date'] = pd.to_datetime(df['user.created_at'], errors='coerce', utc=True).dt.tz_localize(None)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Tokenization BERT ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Construction du Modèle Hybride ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['activation_13', 'vocab_transform', 'vocab_layer_norm', 'vocab_projector']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)     [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_hid   6636288   ['input_ids[0][0]',           \n",
            " stilBertModel)              den_state=(None, 64, 768),   0          'input_mask[0][0]']          \n",
            "                              hidden_states=None, atten                                           \n",
            "                             tions=None)                                                          \n",
            "                                                                                                  \n",
            " input_meta (InputLayer)     [(None, 10)]                 0         []                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  (None, 768)                  0         ['tf_distil_bert_model[0][0]']\n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   352       ['input_meta[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)        (None, 768)                  0         ['tf.__operators__.getitem[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dropout_20 (Dropout)        (None, 32)                   0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 800)                  0         ['dropout_19[0][0]',          \n",
            "                                                                     'dropout_20[0][0]']          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   51264     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_21 (Dropout)        (None, 64)                   0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    65        ['dropout_21[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66414561 (253.35 MB)\n",
            "Trainable params: 66414561 (253.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "--- Début de l'entraînement ---\n",
            "Epoch 1/4\n",
            "7746/7746 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7597"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7746/7746 [==============================] - 1077s 135ms/step - loss: 0.5040 - accuracy: 0.7597 - val_loss: 0.4296 - val_accuracy: 0.8107\n",
            "Epoch 2/4\n",
            "7746/7746 [==============================] - 1017s 131ms/step - loss: 0.4224 - accuracy: 0.8149 - val_loss: 0.4092 - val_accuracy: 0.8204\n",
            "Epoch 3/4\n",
            "7746/7746 [==============================] - 1014s 131ms/step - loss: 0.3830 - accuracy: 0.8355 - val_loss: 0.4362 - val_accuracy: 0.8146\n",
            "Epoch 4/4\n",
            "7746/7746 [==============================] - 997s 129ms/step - loss: 0.3293 - accuracy: 0.8626 - val_loss: 0.4560 - val_accuracy: 0.8089\n",
            "--- Prédiction Finale ---\n",
            "6462/6462 [==============================] - 271s 42ms/step\n",
            "Fichier 'submission_BERT_Hybrid.csv' généré avec succès !\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}